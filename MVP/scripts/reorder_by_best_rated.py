#!/usr/bin/env python3
"""
æŒ‰ç…§ Royal Road Best Rated æ¦œå•é¡ºåºé‡æ–°æ’åˆ—ä¹¦ç±
ä½¿ç”¨éå¸¸ä¿å®ˆçš„ç­–ç•¥ä»¥é¿å…è¢«ç½‘ç«™å°ç¦
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import re
from urllib.parse import urljoin
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# User-Agent æ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.9',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1'
}

BASE_URL = "https://www.royalroad.com"


def create_session():
    """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ Session"""
    session = requests.Session()

    retry_strategy = Retry(
        total=5,
        backoff_factor=10,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS"]
    )

    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    session.headers.update(HEADERS)

    return session


def get_soup(session, url, retry_count=3):
    """è·å–é¡µé¢å¹¶è¿”å› BeautifulSoup å¯¹è±¡"""
    for attempt in range(retry_count):
        try:
            response = session.get(url, timeout=30)
            response.raise_for_status()
            return BeautifulSoup(response.content, 'html.parser')
        except Exception as e:
            print(f"    âŒ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retry_count}): {e}")
            if attempt < retry_count - 1:
                wait_time = (attempt + 1) * 15
                print(f"    â± ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                raise


def random_delay(min_sec=20, max_sec=30):
    """éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«å°"""
    delay = random.uniform(min_sec, max_sec)
    print(f"    â± ç­‰å¾… {delay:.1f} ç§’...")
    time.sleep(delay)


def get_best_rated_order(session):
    """è·å– Best Rated æ¦œå•çš„ä¹¦ç±é¡ºåºï¼ˆå‰8é¡µï¼‰"""
    print("ğŸš€ æ­£åœ¨è·å– Best Rated æ¦œå•é¡ºåº...")
    print("=" * 80)

    ordered_books = {}  # {url: rank}
    page_size = 20

    for page in range(1, 9):
        print(f"\nğŸ“– æ­£åœ¨æŠ“å–ç¬¬ {page}/8 é¡µ...")

        url = f"{BASE_URL}/fictions/best-rated?page={page}"

        try:
            soup = get_soup(session, url)

            # æŸ¥æ‰¾æ‰€æœ‰å°è¯´é“¾æ¥ - Royal Road ä½¿ç”¨ /fiction/æ•°å­—/ä¹¦å æ ¼å¼
            # å…ˆæ‰¾åˆ°æ‰€æœ‰å°è¯´ID
            fiction_ids = re.findall(r'href="/fiction/(\d+)"', str(soup))

            # å»é‡
            unique_ids = list(dict.fromkeys(fiction_ids))

            for fiction_id in unique_ids:
                full_url = f"{BASE_URL}/fiction/{fiction_id}"

                if full_url not in ordered_books:
                    rank = len(ordered_books) + 1
                    ordered_books[full_url] = rank

                    # å°è¯•æ‰¾åˆ°å¯¹åº”çš„æ ‡é¢˜
                    if rank <= (page * 3):
                        title_elem = soup.find('a', href=lambda x: x and f'/fiction/{fiction_id}' in x)
                        if title_elem:
                            title = title_elem.get_text(strip=True)[:30]
                            print(f"       [{rank}] {title}...")
                        else:
                            print(f"       [{rank}] ID: {fiction_id}...")

            print(f"    ğŸ“š æœ¬é¡µæ‰¾åˆ° {len(unique_ids)} æœ¬æ–°ä¹¦ï¼Œç´¯è®¡ {len(ordered_books)} æœ¬")

        except Exception as e:
            print(f"    âŒ ç¬¬ {page} é¡µæŠ“å–å¤±è´¥: {e}")
            continue

        # é¡µé¢ä¹‹é—´å»¶è¿Ÿ
        if page < 8:
            random_delay()

    print(f"\nâœ… å…±è·å– {len(ordered_books)} æœ¬ä¹¦çš„æ¦œå•é¡ºåº")
    return ordered_books


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ”„ æŒ‰ç…§ Royal Road Best Rated æ¦œå•é‡æ–°æ’åˆ—ä¹¦ç±")
    print("=" * 80)

    # è¯»å–ç°æœ‰çš„ Excel æ–‡ä»¶
    input_file = '/Users/chengwen/Projects/solo-sonar/scripts/rr_best_rated.xlsx'
    print(f"\nğŸ“‚ è¯»å–æ–‡ä»¶: {input_file}")

    df = pd.read_excel(input_file)
    print(f"âœ… è¯»å–æˆåŠŸï¼Œå…± {len(df)} æœ¬ä¹¦")

    # åˆ›å»º Session
    session = create_session()
    print("âœ… å·²åˆ›å»º HTTP Session")

    # è·å– Best Rated æ¦œå•çš„åŸå§‹é¡ºåº
    ordered_books = get_best_rated_order(session)

    # ä¸ºæ¯æœ¬ä¹¦æ·»åŠ æ¦œå•æ’å
    df['best_rank'] = df['url'].map(ordered_books)

    # ç»Ÿè®¡æœ‰å¤šå°‘æœ¬ä¹¦æ‰¾åˆ°äº†æ’å
    found_rank = df['best_rank'].notna().sum()
    not_found = len(df) - found_rank

    print(f"\nğŸ“Š åœ¨æ¦œå•ä¸­æ‰¾åˆ° {found_rank}/{len(df)} æœ¬ä¹¦çš„æ’å")
    if not_found > 0:
        print(f"âš ï¸  æœ‰ {not_found} æœ¬ä¹¦æœªåœ¨æ¦œå•å‰8é¡µä¸­æ‰¾åˆ°")

    # æ˜¾ç¤ºä¸€äº›æ‰¾åˆ°çš„å’Œæœªæ‰¾åˆ°çš„ä¹¦ç±ç¤ºä¾‹
    if found_rank > 0:
        print("\nâœ… æˆåŠŸåŒ¹é…çš„ä¹¦ç±ç¤ºä¾‹ï¼ˆå‰5æœ¬ï¼‰:")
        found_df = df[df['best_rank'].notna()].sort_values('best_rank').head(5)
        for idx, row in found_df.iterrows():
            print(f"   [æ’å {int(row['best_rank'])}] {row['title'][:40]}")

    if not_found > 0:
        print("\nâš ï¸  æœªåœ¨æ¦œå•ä¸­æ‰¾åˆ°çš„ä¹¦ç±ç¤ºä¾‹:")
        not_found_df = df[df['best_rank'].isna()].head(5)
        for idx, row in not_found_df.iterrows():
            print(f"   - {row['title'][:40]}")

    # æŒ‰ç…§ Best Rated æ¦œå•é¡ºåºæ’åºï¼ˆæ²¡æœ‰æ’åçš„æ”¾åœ¨æœ€åï¼‰
    df_sorted = df.sort_values(by='best_rank', ascending=True, na_position='last')

    # åˆ é™¤ä¸´æ—¶åˆ—
    df_sorted = df_sorted.drop(columns=['best_rank'])

    # ä¿æŒåŸæœ‰çš„åˆ—é¡ºåº
    columns_order = df.columns.tolist()
    df_sorted = df_sorted[columns_order]

    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    output_file = input_file
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜åˆ° {output_file}...")

    df_sorted.to_excel(output_file, index=False, engine='openpyxl')
    print("âœ… ä¿å­˜æˆåŠŸï¼")

    # æ˜¾ç¤ºé¢„è§ˆ
    print("\n" + "=" * 80)
    print("ğŸ“Š é‡æ–°æ’åºåçš„æ•°æ®é¢„è§ˆï¼ˆå‰15æœ¬ï¼‰:")
    print("=" * 80)
    print(df_sorted[['title', 'views', 'followers']].head(15).to_string())

    print("\n" + "=" * 80)
    print("âœ… å®Œæˆï¼")
    print(f"ğŸ“ æ–‡ä»¶å·²æ›´æ–°: {output_file}")
    print(f"ğŸ“š å…± {len(df_sorted)} æœ¬ä¹¦")
    print(f"ğŸ“ˆ æŒ‰ Best Rated æ¦œå•é¡ºåºæ’åˆ—")
    print("=" * 80)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
