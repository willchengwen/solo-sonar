#!/usr/bin/env python3
"""
æ›´æ–° Royal Road ä¹¦ç±çš„è¯„åˆ†æ•°æ®ï¼Œå¹¶æŒ‰ç…§ Best Rated æ¦œå•é¡ºåºé‡æ–°æ’åˆ—
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
from urllib.parse import urljoin
import re

# User-Agent æ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.9',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
    'Sec-Fetch-Dest': 'document',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Site': 'none',
    'Cache-Control': 'max-age=0'
}

BASE_URL = "https://www.royalroad.com"


def random_delay(min_sec=3, max_sec=6):
    """éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«å°"""
    delay = random.uniform(min_sec, max_sec)
    print(f"    â± ç­‰å¾… {delay:.1f} ç§’...")
    time.sleep(delay)


def get_soup(url, retry_count=3):
    """è·å–é¡µé¢å¹¶è¿”å› BeautifulSoup å¯¹è±¡"""
    for attempt in range(retry_count):
        try:
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.raise_for_status()
            return BeautifulSoup(response.content, 'html.parser')
        except Exception as e:
            print(f"    âŒ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retry_count}): {e}")
            if attempt < retry_count - 1:
                time.sleep(random.uniform(3, 6))
            else:
                raise


def get_book_rating(url):
    """è·å–ä¹¦ç±è¯¦æƒ…é¡µçš„è¯„åˆ†"""
    try:
        soup = get_soup(url)

        # è¯„åˆ† - æŸ¥æ‰¾è¯„åˆ†å…ƒç´ 
        rating = None
        rating_element = soup.find('span', class_=lambda x: x and 'rating' in x.lower())
        if rating_element:
            rating_text = rating_element.get_text(strip=True)
            rating_match = re.search(r'([\d.]+)', rating_text)
            if rating_match:
                rating = float(rating_match.group(1))

        # å¦ä¸€ç§å°è¯•ï¼šæŸ¥æ‰¾æ‰€æœ‰åŒ…å«è¯„åˆ†çš„å…ƒç´ 
        if not rating:
            # æŸ¥æ‰¾ fiction-rating ç±»
            rating_elements = soup.find_all(class_=lambda x: x and 'rating' in str(x).lower())
            for elem in rating_elements:
                text = elem.get_text(strip=True)
                # åŒ¹é…ç±»ä¼¼ "4.5" æˆ– "4.5 (1000 ratings)" çš„æ ¼å¼
                match = re.search(r'(\d\.\d{1,2})', text)
                if match:
                    rating = float(match.group(1))
                    break

        return rating
    except Exception as e:
        print(f"    âš ï¸ è·å–è¯„åˆ†å¤±è´¥: {e}")
        return None


def get_best_rated_order():
    """è·å– Best Rated æ¦œå•çš„ä¹¦ç±é¡ºåºï¼ˆå‰8é¡µï¼‰"""
    print("ğŸš€ æ­£åœ¨è·å– Best Rated æ¦œå•é¡ºåº...")

    ordered_books = {}  # {url: rank}

    for page in range(1, 9):
        print(f"\nğŸ“– æ­£åœ¨æŠ“å–ç¬¬ {page}/8 é¡µçš„æ¦œå•é¡ºåº...")

        url = f"{BASE_URL}/fictions/best-rated?page={page}"
        soup = get_soup(url)

        # æŸ¥æ‰¾æ‰€æœ‰å°è¯´æ¡ç›®
        book_elements = soup.find_all('div', class_='fiction-card')

        if not book_elements:
            book_elements = soup.find_all('div', class_='row')
            book_elements = [elem for elem in book_elements if elem.find('h2')]

        print(f"    ğŸ“š æ‰¾åˆ° {len(book_elements)} æœ¬ä¹¦")

        for idx, book_elem in enumerate(book_elements, 1):
            try:
                title_link = book_elem.find('h2').find('a') if book_elem.find('h2') else None
                if title_link:
                    link = title_link.get('href')
                    full_url = urljoin(BASE_URL, link)
                    rank = (page - 1) * 20 + idx
                    ordered_books[full_url] = rank
            except:
                pass

        if page < 8:
            random_delay(1, 2)

    print(f"\nâœ… å…±è·å– {len(ordered_books)} æœ¬ä¹¦çš„æ¦œå•é¡ºåº")
    return ordered_books


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ”„ æ›´æ–° Royal Road ä¹¦ç±è¯„åˆ†å¹¶é‡æ–°æ’åº")
    print("=" * 80)

    # è¯»å–ç°æœ‰çš„ Excel æ–‡ä»¶
    input_file = '/Users/chengwen/Projects/solo-sonar/scripts/rr_best_rated.xlsx'
    print(f"\nğŸ“‚ è¯»å–æ–‡ä»¶: {input_file}")

    df = pd.read_excel(input_file)
    print(f"âœ… è¯»å–æˆåŠŸï¼Œå…± {len(df)} æœ¬ä¹¦")

    # 1. è·å– Best Rated æ¦œå•çš„åŸå§‹é¡ºåº
    print("\n" + "=" * 80)
    ordered_books = get_best_rated_order()

    # 2. ä¸ºæ¯æœ¬ä¹¦æ·»åŠ æ¦œå•æ’å
    df['best_rank'] = df['url'].map(ordered_books)

    # ç»Ÿè®¡æœ‰å¤šå°‘æœ¬ä¹¦æ‰¾åˆ°äº†æ’å
    found_rank = df['best_rank'].notna().sum()
    print(f"\nğŸ“Š åœ¨æ¦œå•ä¸­æ‰¾åˆ° {found_rank}/{len(df)} æœ¬ä¹¦çš„æ’å")

    # 3. è·å–æ¯æœ¬ä¹¦çš„è¯„åˆ†
    print("\n" + "=" * 80)
    print("ğŸ“ˆ å¼€å§‹æŠ“å–è¯„åˆ†æ•°æ®...")
    print("=" * 80)

    ratings = {}

    for idx, row in df.iterrows():
        print(f"\n[{idx + 1}/{len(df)}] æ­£åœ¨è·å–è¯„åˆ†: {row['title'][:40]}...")

        try:
            rating = get_book_rating(row['url'])
            if rating:
                ratings[row['url']] = rating
                print(f"    âœ“ è¯„åˆ†: {rating}")
            else:
                print(f"    âš ï¸ æœªæ‰¾åˆ°è¯„åˆ†")
                ratings[row['url']] = None

            # å»¶è¿Ÿ
            if idx < len(df) - 1:
                random_delay(1, 3)

        except Exception as e:
            print(f"    âŒ å‡ºé”™: {e}")
            ratings[row['url']] = None

    # æ·»åŠ è¯„åˆ†åˆ—
    df['platformRating'] = df['url'].map(ratings)

    # ç»Ÿè®¡è¯„åˆ†æƒ…å†µ
    has_rating = df['platformRating'].notna().sum()
    print(f"\nğŸ“Š æˆåŠŸè·å– {has_rating}/{len(df)} æœ¬ä¹¦çš„è¯„åˆ†")

    # 4. æŒ‰ç…§ Best Rated æ¦œå•é¡ºåºæ’åºï¼ˆæ²¡æœ‰æ’åçš„æ”¾åœ¨æœ€åï¼‰
    df_sorted = df.sort_values(by='best_rank', ascending=True, na_position='last')

    # åˆ é™¤ä¸´æ—¶åˆ—
    df_sorted = df_sorted.drop(columns=['best_rank'])

    # è°ƒæ•´åˆ—é¡ºåºï¼ŒæŠŠè¯„åˆ†æ”¾åœ¨æ›´åˆç†çš„ä½ç½®
    columns_order = [
        'title', 'author', 'url', 'coverUrl',
        'platformRating',  # è¯„åˆ†æ”¾åœ¨è¿™é‡Œ
        'status', 'chapters', 'pages', 'words',
        'views', 'followers', 'synopsis',
        'tags', 'notes'  # notes æ”¾åœ¨æœ€å
    ]

    # åªä¿ç•™å­˜åœ¨çš„åˆ—
    columns_order = [col for col in columns_order if col in df_sorted.columns]
    df_sorted = df_sorted[columns_order]

    # 5. ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    output_file = input_file
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜åˆ° {output_file}...")

    df_sorted.to_excel(output_file, index=False, engine='openpyxl')
    print("âœ… ä¿å­˜æˆåŠŸï¼")

    # 6. æ˜¾ç¤ºé¢„è§ˆ
    print("\n" + "=" * 80)
    print("ğŸ“Š æ›´æ–°åçš„æ•°æ®é¢„è§ˆï¼ˆå‰10æœ¬ï¼‰:")
    print("=" * 80)
    print(df_sorted[['title', 'platformRating', 'followers', 'views']].head(10).to_string())

    print("\n" + "=" * 80)
    print("âœ… å®Œæˆï¼")
    print(f"ğŸ“ æ–‡ä»¶å·²æ›´æ–°: {output_file}")
    print(f"ğŸ“š å…± {len(df_sorted)} æœ¬ä¹¦")
    print(f"â­ æœ‰è¯„åˆ†: {has_rating} æœ¬")
    print(f"ğŸ“ˆ æŒ‰ Best Rated æ¦œå•é¡ºåºæ’åˆ—")
    print("=" * 80)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
