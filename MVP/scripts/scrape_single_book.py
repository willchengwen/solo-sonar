#!/usr/bin/env python3
"""
æŠ“å–å•æœ¬ä¹¦ç±æ•°æ® - Worth the Candle by Alexander Wales
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import json

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.9',
    'Connection': 'keep-alive'
}

BASE_URL = "https://www.royalroad.com"


def search_book(title, author=None):
    """æœç´¢ä¹¦ç±"""
    print(f"ğŸ” æœç´¢ä¹¦ç±: {title}")
    if author:
        print(f"   ä½œè€…: {author}")

    # ä½¿ç”¨ Royal Road æœç´¢
    search_url = f"{BASE_URL}/fictions/search"
    params = {'title': title}

    try:
        response = requests.get(search_url, params=params, headers=HEADERS, timeout=30)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        # æŸ¥æ‰¾æ‰€æœ‰å°è¯´é“¾æ¥
        fiction_links = soup.find_all('a', href=lambda x: x and '/fiction/' in str(x))

        print(f"\n   æ‰¾åˆ° {len(fiction_links)} ä¸ªç»“æœ")

        for link in fiction_links[:10]:  # åªçœ‹å‰10ä¸ªç»“æœ
            link_text = link.get_text(strip=True).lower()
            if title.lower() in link_text:
                href = link.get('href')
                full_url = f"{BASE_URL}{href}"
                print(f"\nâœ… æ‰¾åˆ°åŒ¹é…: {link.get_text(strip=True)}")
                print(f"   URL: {full_url}")
                return full_url

        # å¦‚æœæ²¡æœ‰å®Œå…¨åŒ¹é…ï¼Œæ˜¾ç¤ºæ‰€æœ‰ç»“æœ
        print("\nğŸ“‹ æœç´¢ç»“æœ:")
        for i, link in enumerate(fiction_links[:5], 1):
            href = link.get('href')
            if href and '/fiction/' in href:
                full_url = f"{BASE_URL}{href}"
                print(f"   {i}. {link.get_text(strip=True)}")
                print(f"      {full_url}")

        return None

    except Exception as e:
        print(f"âŒ æœç´¢å¤±è´¥: {e}")
        return None


def scrape_book(url):
    """æŠ“å–å•æœ¬ä¹¦çš„å®Œæ•´ä¿¡æ¯"""
    print(f"\nğŸ“– æ­£åœ¨æŠ“å–ä¹¦ç±ä¿¡æ¯...")
    print(f"   URL: {url}")

    try:
        response = requests.get(url, headers=HEADERS, timeout=30)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        # åŸºæœ¬ä¿¡æ¯
        title = None
        title_elem = soup.find('h1', class_='font-white') or soup.find('h1')
        if title_elem:
            title = title_elem.get_text(strip=True)

        # ä½œè€…
        author = None
        author_link = soup.find('a', href=lambda x: x and '/profile/' in str(x))
        if author_link:
            author = author_link.get_text(strip=True)

        # çŠ¶æ€
        status = None
        all_text = soup.get_text()
        for status_type in ["COMPLETED", "ONGOING", "HIATUS", "STUB", "STUBBED"]:
            if status_type in all_text:
                status = status_type
                break

        # å°é¢
        cover_url = None
        cover_img = soup.find('img', class_='img-responsive')
        if cover_img:
            cover_url = cover_img.get('src')

        # è¯„åˆ†
        rating = None
        meta_rating = soup.find('meta', property='books:rating:value')
        if meta_rating and meta_rating.get('content'):
            try:
                rating = float(meta_rating['content'])
            except:
                pass

        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯• JSON-LD
        if not rating:
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld:
                try:
                    data = json.loads(json_ld.string)
                    if 'aggregateRating' in data:
                        rating = float(data['aggregateRating']['ratingValue'])
                except:
                    pass

        # ç»Ÿè®¡ä¿¡æ¯
        stats_section = soup.find('div', class_='fiction-stats')
        chapters = None
        pages = None
        words = None
        views = None
        followers = None

        if stats_section:
            stats_text = stats_section.get_text()

            # ç« èŠ‚å’Œé¡µæ•°
            chapters_match = re.search(r'(\d+)\s*(Chapters|Chapter)', stats_text, re.IGNORECASE)
            if chapters_match:
                chapters = int(chapters_match.group(1))

            pages_match = re.search(r'(\d+)\s*(Pages|Page)', stats_text, re.IGNORECASE)
            if pages_match:
                pages = int(pages_match.group(1))

            # å­—æ•°
            words_match = re.search(r'([\d,]+)\s*Words?', stats_text, re.IGNORECASE)
            if words_match:
                words = int(words_match.group(1).replace(',', ''))

        # æŸ¥æ‰¾æµè§ˆé‡å’Œå…³æ³¨è€…
        for elem in soup.find_all(['div', 'span', 'p']):
            text = elem.get_text(strip=True)

            if not views:
                views_match = re.search(r'([\d,]+)\s*Views?', text, re.IGNORECASE)
                if views_match:
                    views = int(views_match.group(1).replace(',', ''))

            if not followers:
                followers_match = re.search(r'([\d,]+)\s*Followers?', text, re.IGNORECASE)
                if followers_match:
                    followers = int(followers_match.group(1).replace(',', ''))

        # ç®€ä»‹
        synopsis = None
        synopsis_elem = soup.find('div', class_='fiction-description')
        if synopsis_elem:
            synopsis = synopsis_elem.get_text(strip=True)[:1000]

        # æ ‡ç­¾
        tags = []
        tag_links = soup.find_all('a', href=lambda x: x and '/tags/' in str(x))
        for tag_elem in tag_links[:10]:
            tag_text = tag_elem.get_text(strip=True)
            if tag_text and tag_text not in tags:
                tags.append(tag_text)

        book_info = {
            'title': title,
            'author': author,
            'url': url,
            'coverUrl': cover_url,
            'status': status,
            'chapters': chapters,
            'pages': pages,
            'words': words,
            'views': views,
            'followers': followers,
            'synopsis': synopsis,
            'platformRating': rating,
            'tags': ', '.join(tags) if tags else None
        }

        return book_info

    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def save_to_excel(book_info, filename="worth_the_candle.xlsx"):
    """ä¿å­˜åˆ° Excel"""
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜åˆ° {filename}...")

    df = pd.DataFrame([book_info])

    # è°ƒæ•´åˆ—é¡ºåº
    columns_order = [
        'title', 'author', 'url', 'coverUrl',
        'platformRating',
        'status', 'chapters', 'pages', 'words',
        'views', 'followers', 'synopsis',
        'tags'
    ]

    columns_order = [col for col in columns_order if col in df.columns]
    df = df[columns_order]

    df.to_excel(filename, index=False, engine='openpyxl')
    print("âœ… ä¿å­˜æˆåŠŸï¼")

    # æ˜¾ç¤ºä¿¡æ¯
    print("\n" + "=" * 80)
    print("ğŸ“Š ä¹¦ç±ä¿¡æ¯:")
    print("=" * 80)
    for key, value in book_info.items():
        if value and value != 'None':
            print(f"{key:15}: {value}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ“š æŠ“å–ä¹¦ç±æ•°æ® - Worth the Candle by Alexander Wales")
    print("=" * 80)

    # æ–¹æ³•1ï¼šå°è¯•å·²çŸ¥çš„URL
    # Worth the Candle å¸¸è§çš„IDæ˜¯28581æˆ–20174
    possible_urls = [
        "https://www.royalroad.com/fiction/28581",
        "https://www.royalroad.com/fiction/20174/worth-the-candle",
    ]

    book_url = None

    for url in possible_urls:
        print(f"\nå°è¯•è®¿é—®: {url}")
        try:
            response = requests.get(url, headers=HEADERS, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¹¦å
                if "worth the candle" in soup.get_text().lower():
                    print("âœ… æ‰¾åˆ°ä¹¦ç±ï¼")
                    book_url = url
                    break
        except:
            continue

    # æ–¹æ³•2ï¼šå¦‚æœç›´æ¥URLä¸å·¥ä½œï¼Œä½¿ç”¨æœç´¢
    if not book_url:
        book_url = search_book("Worth the Candle", "Alexander Wales")

    if not book_url:
        print("\nâŒ æœªæ‰¾åˆ°ä¹¦ç±")
        return

    # æŠ“å–ä¹¦ç±ä¿¡æ¯
    book_info = scrape_book(book_url)

    if book_info:
        # ä¿å­˜åˆ° Excel
        save_to_excel(book_info)

        print("\n" + "=" * 80)
        print("âœ… å®Œæˆï¼")
        print("=" * 80)
    else:
        print("âŒ æŠ“å–å¤±è´¥")


if __name__ == "__main__":
    main()
